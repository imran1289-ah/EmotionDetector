Using device: cuda

Training and evaluating model: CNN
Starting fold 1
Fold 1, Epoch 1, Training loss: 0.8810987823304877
Fold 1, Epoch 2, Training loss: 0.47881606234385904
Fold 1, Epoch 3, Training loss: 0.3244928162446064
Fold 1, Epoch 4, Training loss: 0.20653108513988225
Fold 1, Epoch 5, Training loss: 0.1354277050699544
Fold 1, Epoch 6, Training loss: 0.09125295816714653
Fold 1, Epoch 7, Training loss: 0.06987253986134202
Fold 1, Epoch 8, Training loss: 0.03704653957351811
Fold 1, Epoch 9, Training loss: 0.034183922381371065
Fold 1, Epoch 10, Training loss: 0.032387191913038106
Fold 1 completed in 152.16 seconds. Validation Accuracy: 87.0%
Starting fold 2
Fold 2, Epoch 1, Training loss: 0.806832647956578
Fold 2, Epoch 2, Training loss: 0.42505009788854986
Fold 2, Epoch 3, Training loss: 0.2737397716372414
Fold 2, Epoch 4, Training loss: 0.1815778640453267
Fold 2, Epoch 5, Training loss: 0.09968540163925
Fold 2, Epoch 6, Training loss: 0.07314366666781427
Fold 2, Epoch 7, Training loss: 0.04984539620005485
Fold 2, Epoch 8, Training loss: 0.05530034431124485
Fold 2, Epoch 9, Training loss: 0.0415876381519298
Fold 2, Epoch 10, Training loss: 0.05080208265989096
Fold 2 completed in 152.91 seconds. Validation Accuracy: 84.5%
Starting fold 3
Fold 3, Epoch 1, Training loss: 0.8334174464761683
Fold 3, Epoch 2, Training loss: 0.4288258673870458
Fold 3, Epoch 3, Training loss: 0.30068833598520905
Fold 3, Epoch 4, Training loss: 0.19099392166641432
Fold 3, Epoch 5, Training loss: 0.10703396794707638
Fold 3, Epoch 6, Training loss: 0.07536357527483353
Fold 3, Epoch 7, Training loss: 0.040729903475900664
Fold 3, Epoch 8, Training loss: 0.07256781088344885
Fold 3, Epoch 9, Training loss: 0.03564053805353351
Fold 3, Epoch 10, Training loss: 0.035406705996009265
Fold 3 completed in 154.77 seconds. Validation Accuracy: 85.25%
Starting fold 4
Fold 4, Epoch 1, Training loss: 0.8355797260208467
Fold 4, Epoch 2, Training loss: 0.45971297057329025
Fold 4, Epoch 3, Training loss: 0.32620560694321066
Fold 4, Epoch 4, Training loss: 0.23177951158939208
Fold 4, Epoch 5, Training loss: 0.16465443583716333
Fold 4, Epoch 6, Training loss: 0.08779082152234242
Fold 4, Epoch 7, Training loss: 0.04932429772323673
Fold 4, Epoch 8, Training loss: 0.05901237310165853
Fold 4, Epoch 9, Training loss: 0.023732581822071802
Fold 4, Epoch 10, Training loss: 0.04806929892722303
Fold 4 completed in 153.50 seconds. Validation Accuracy: 85.25%
Starting fold 5
Fold 5, Epoch 1, Training loss: 0.8233957459441329
Fold 5, Epoch 2, Training loss: 0.47303395197454806
Fold 5, Epoch 3, Training loss: 0.32510946216308967
Fold 5, Epoch 4, Training loss: 0.2068772679277226
Fold 5, Epoch 5, Training loss: 0.15137248252213528
Fold 5, Epoch 6, Training loss: 0.11878383672276957
Fold 5, Epoch 7, Training loss: 0.09161497712695757
Fold 5, Epoch 8, Training loss: 0.06975814935017739
Fold 5, Epoch 9, Training loss: 0.0635563658418513
Fold 5, Epoch 10, Training loss: 0.046131567766815755
Fold 5 completed in 154.83 seconds. Validation Accuracy: 86.5%
Starting fold 6
Fold 6, Epoch 1, Training loss: 0.7940310329462574
Fold 6, Epoch 2, Training loss: 0.4448822960916874
Fold 6, Epoch 3, Training loss: 0.33353211727421894
Fold 6, Epoch 4, Training loss: 0.2303461988942813
Fold 6, Epoch 5, Training loss: 0.1514910689299613
Fold 6, Epoch 6, Training loss: 0.08820573431728161
Fold 6, Epoch 7, Training loss: 0.057860081159278945
Fold 6, Epoch 8, Training loss: 0.053375271010929634
Fold 6, Epoch 9, Training loss: 0.03177087670305447
Fold 6, Epoch 10, Training loss: 0.03146753524609355
Fold 6 completed in 156.46 seconds. Validation Accuracy: 83.5%
Starting fold 7
Fold 7, Epoch 1, Training loss: 0.815156366445322
Fold 7, Epoch 2, Training loss: 0.46086561323794645
Fold 7, Epoch 3, Training loss: 0.37065276450815454
Fold 7, Epoch 4, Training loss: 0.2616321873084634
Fold 7, Epoch 5, Training loss: 0.2028011380637114
Fold 7, Epoch 6, Training loss: 0.12315650589236643
Fold 7, Epoch 7, Training loss: 0.07484802075216662
Fold 7, Epoch 8, Training loss: 0.05682749748312398
Fold 7, Epoch 9, Training loss: 0.04565436275989081
Fold 7, Epoch 10, Training loss: 0.03672617410291069
Fold 7 completed in 153.39 seconds. Validation Accuracy: 85.0%
Starting fold 8
Fold 8, Epoch 1, Training loss: 0.8205114088754738
Fold 8, Epoch 2, Training loss: 0.44778792335923795
Fold 8, Epoch 3, Training loss: 0.3160852546581125
Fold 8, Epoch 4, Training loss: 0.21337279393873385
Fold 8, Epoch 5, Training loss: 0.10843278045675396
Fold 8, Epoch 6, Training loss: 0.06256304034320391
Fold 8, Epoch 7, Training loss: 0.07984173484146595
Fold 8, Epoch 8, Training loss: 0.04500959232136344
Fold 8, Epoch 9, Training loss: 0.029632007276157196
Fold 8, Epoch 10, Training loss: 0.01459643354874302
Fold 8 completed in 155.04 seconds. Validation Accuracy: 81.25%
Starting fold 9
Fold 9, Epoch 1, Training loss: 0.8820376567608488
Fold 9, Epoch 2, Training loss: 0.4648391628159886
Fold 9, Epoch 3, Training loss: 0.34351100258331385
Fold 9, Epoch 4, Training loss: 0.21084560763783158
Fold 9, Epoch 5, Training loss: 0.1286808128048361
Fold 9, Epoch 6, Training loss: 0.08760564505592384
Fold 9, Epoch 7, Training loss: 0.05861882793725328
Fold 9, Epoch 8, Training loss: 0.05144767111488741
Fold 9, Epoch 9, Training loss: 0.04024945757561981
Fold 9, Epoch 10, Training loss: 0.03625804137498289
Fold 9 completed in 151.79 seconds. Validation Accuracy: 84.0%
Starting fold 10
Fold 10, Epoch 1, Training loss: 0.9840097672643915
Fold 10, Epoch 2, Training loss: 0.5069831301153234
Fold 10, Epoch 3, Training loss: 0.4082794938467245
Fold 10, Epoch 4, Training loss: 0.314831833066666
Fold 10, Epoch 5, Training loss: 0.23293948631766623
Fold 10, Epoch 6, Training loss: 0.16204043296454226
Fold 10, Epoch 7, Training loss: 0.10530681999614544
Fold 10, Epoch 8, Training loss: 0.0728794551677013
Fold 10, Epoch 9, Training loss: 0.061627624766587945
Fold 10, Epoch 10, Training loss: 0.056127704795866186
Fold 10 completed in 153.29 seconds. Validation Accuracy: 86.75%

Training and evaluating model: CNN Variant 2
Starting fold 1
Fold 1, Epoch 1, Training loss: 1.3332539912873664
Fold 1, Epoch 2, Training loss: 1.2224856915727127
Fold 1, Epoch 3, Training loss: 0.979925720565087
Fold 1, Epoch 4, Training loss: 0.9060873668805688
Fold 1, Epoch 5, Training loss: 0.8467609191362837
Fold 1, Epoch 6, Training loss: 0.7849999982698829
Fold 1, Epoch 7, Training loss: 0.7086712868340248
Fold 1, Epoch 8, Training loss: 0.674151526615683
Fold 1, Epoch 9, Training loss: 0.6904397155858774
Fold 1, Epoch 10, Training loss: 0.6217841192156868
Fold 1 completed in 173.29 seconds. Validation Accuracy: 77.0%
Starting fold 2
Fold 2, Epoch 1, Training loss: 1.3263172544209303
Fold 2, Epoch 2, Training loss: 1.1034270219043292
Fold 2, Epoch 3, Training loss: 0.8995954695001113
Fold 2, Epoch 4, Training loss: 0.8276300082164528
Fold 2, Epoch 5, Training loss: 0.7902992314996973
Fold 2, Epoch 6, Training loss: 0.7397266871633783
Fold 2, Epoch 7, Training loss: 0.7278648614883423
Fold 2, Epoch 8, Training loss: 0.6745725007711258
Fold 2, Epoch 9, Training loss: 0.6457772405274147
Fold 2, Epoch 10, Training loss: 0.6335364580154419
Fold 2 completed in 174.40 seconds. Validation Accuracy: 70.75%
Starting fold 3
Fold 3, Epoch 1, Training loss: 1.3224698305130005
Fold 3, Epoch 2, Training loss: 1.2055293210839804
Fold 3, Epoch 3, Training loss: 1.006176040235874
Fold 3, Epoch 4, Training loss: 0.914815612598858
Fold 3, Epoch 5, Training loss: 0.8546561066028291
Fold 3, Epoch 6, Training loss: 0.7879087444955268
Fold 3, Epoch 7, Training loss: 0.7740533510140614
Fold 3, Epoch 8, Training loss: 0.7337593248987619
Fold 3, Epoch 9, Training loss: 0.6900437052271008
Fold 3, Epoch 10, Training loss: 0.6293352842330933
Fold 3 completed in 180.13 seconds. Validation Accuracy: 73.25%
Starting fold 4
Fold 4, Epoch 1, Training loss: 1.3410291386916575
Fold 4, Epoch 2, Training loss: 1.2178789730620596
Fold 4, Epoch 3, Training loss: 1.0319656254970921
Fold 4, Epoch 4, Training loss: 0.9083241430004086
Fold 4, Epoch 5, Training loss: 0.8721644820365231
Fold 4, Epoch 6, Training loss: 0.7866222679087546
Fold 4, Epoch 7, Training loss: 0.7142658534303176
Fold 4, Epoch 8, Training loss: 0.675468599110578
Fold 4, Epoch 9, Training loss: 0.637095573465381
Fold 4, Epoch 10, Training loss: 0.593627451531655
Fold 4 completed in 170.64 seconds. Validation Accuracy: 75.25%
Starting fold 5
Fold 5, Epoch 1, Training loss: 1.340870556578172
Fold 5, Epoch 2, Training loss: 1.2538301438356922
Fold 5, Epoch 3, Training loss: 1.0996166889646413
Fold 5, Epoch 4, Training loss: 0.9195930657133592
Fold 5, Epoch 5, Training loss: 0.8365886717771007
Fold 5, Epoch 6, Training loss: 0.780019590284972
Fold 5, Epoch 7, Training loss: 0.740499689515713
Fold 5, Epoch 8, Training loss: 0.7009013582647374
Fold 5, Epoch 9, Training loss: 0.6462541686750092
Fold 5, Epoch 10, Training loss: 0.6171733620947442
Fold 5 completed in 171.38 seconds. Validation Accuracy: 72.75%
Starting fold 6
Fold 6, Epoch 1, Training loss: 1.3145336925455955
Fold 6, Epoch 2, Training loss: 1.0722985932257323
Fold 6, Epoch 3, Training loss: 0.9100064645826289
Fold 6, Epoch 4, Training loss: 0.8425461612971483
Fold 6, Epoch 5, Training loss: 0.8107208957714317
Fold 6, Epoch 6, Training loss: 0.7665636315282467
Fold 6, Epoch 7, Training loss: 0.7002917314525199
Fold 6, Epoch 8, Training loss: 0.6942585039455279
Fold 6, Epoch 9, Training loss: 0.6625960202871171
Fold 6, Epoch 10, Training loss: 0.6009919820106135
Fold 6 completed in 172.87 seconds. Validation Accuracy: 73.0%
Starting fold 7
Fold 7, Epoch 1, Training loss: 1.329896829824532
Fold 7, Epoch 2, Training loss: 1.2327859391153386
Fold 7, Epoch 3, Training loss: 1.0661913367499292
Fold 7, Epoch 4, Training loss: 0.918607889550977
Fold 7, Epoch 5, Training loss: 0.863718750730025
Fold 7, Epoch 6, Training loss: 0.802981308076234
Fold 7, Epoch 7, Training loss: 0.7455308848777703
Fold 7, Epoch 8, Training loss: 0.7367121645834593
Fold 7, Epoch 9, Training loss: 0.7061366483701014
Fold 7, Epoch 10, Training loss: 0.679289759787838
Fold 7 completed in 169.97 seconds. Validation Accuracy: 74.25%
Starting fold 8
Fold 8, Epoch 1, Training loss: 1.325995247975915
Fold 8, Epoch 2, Training loss: 1.224339700378148
Fold 8, Epoch 3, Training loss: 1.0626928146961516
Fold 8, Epoch 4, Training loss: 0.9157463992591452
Fold 8, Epoch 5, Training loss: 0.8189356458925567
Fold 8, Epoch 6, Training loss: 0.7524081004404388
Fold 8, Epoch 7, Training loss: 0.6931289977731958
Fold 8, Epoch 8, Training loss: 0.6570682042995385
Fold 8, Epoch 9, Training loss: 0.6356910277256923
Fold 8, Epoch 10, Training loss: 0.5846619067993839
Fold 8 completed in 171.33 seconds. Validation Accuracy: 72.0%
Starting fold 9
Fold 9, Epoch 1, Training loss: 1.3404604038306043
Fold 9, Epoch 2, Training loss: 1.2508206066832077
Fold 9, Epoch 3, Training loss: 1.0843400754759798
Fold 9, Epoch 4, Training loss: 0.9541762835156601
Fold 9, Epoch 5, Training loss: 0.8968584226296011
Fold 9, Epoch 6, Training loss: 0.8017793456010059
Fold 9, Epoch 7, Training loss: 0.7577575344954972
Fold 9, Epoch 8, Training loss: 0.7159600136554347
Fold 9, Epoch 9, Training loss: 0.6442269746181184
Fold 9, Epoch 10, Training loss: 0.6082718723115668
Fold 9 completed in 168.62 seconds. Validation Accuracy: 69.75%
Starting fold 10
Fold 10, Epoch 1, Training loss: 1.315845464183166
Fold 10, Epoch 2, Training loss: 1.17955580643848
Fold 10, Epoch 3, Training loss: 0.9934174956473629
Fold 10, Epoch 4, Training loss: 0.8918810165033931
Fold 10, Epoch 5, Training loss: 0.8372906172170048
Fold 10, Epoch 6, Training loss: 0.7816849622578748
Fold 10, Epoch 7, Training loss: 0.7174387819471613
Fold 10, Epoch 8, Training loss: 0.6769344239635805
Fold 10, Epoch 9, Training loss: 0.6608401571227386
Fold 10, Epoch 10, Training loss: 0.6229351339614497
Fold 10 completed in 169.74 seconds. Validation Accuracy: 75.75%

Training and evaluating model: CNN Variant 3
Starting fold 1
Fold 1, Epoch 1, Training loss: 1.22384332977565
Fold 1, Epoch 2, Training loss: 0.6318847668909393
Fold 1, Epoch 3, Training loss: 0.39328399682994436
Fold 1, Epoch 4, Training loss: 0.27095702277348105
Fold 1, Epoch 5, Training loss: 0.2047499545841618
Fold 1, Epoch 6, Training loss: 0.15052471617319152
Fold 1, Epoch 7, Training loss: 0.10108118895770965
Fold 1, Epoch 8, Training loss: 0.08713607773786428
Fold 1, Epoch 9, Training loss: 0.058036778028178714
Fold 1, Epoch 10, Training loss: 0.09143384912801264
Fold 1 completed in 158.08 seconds. Validation Accuracy: 92.5%
Starting fold 2
Fold 2, Epoch 1, Training loss: 0.88971912597133
Fold 2, Epoch 2, Training loss: 0.43785222758234077
Fold 2, Epoch 3, Training loss: 0.30589689789092644
Fold 2, Epoch 4, Training loss: 0.2313510783478222
Fold 2, Epoch 5, Training loss: 0.15705648209668893
Fold 2, Epoch 6, Training loss: 0.10734824525950624
Fold 2, Epoch 7, Training loss: 0.09045505881787533
Fold 2, Epoch 8, Training loss: 0.07025503102830091
Fold 2, Epoch 9, Training loss: 0.044771320580100984
Fold 2, Epoch 10, Training loss: 0.06112879546759938
Fold 2 completed in 159.01 seconds. Validation Accuracy: 93.5%
Starting fold 3
Fold 3, Epoch 1, Training loss: 0.9515128346671046
Fold 3, Epoch 2, Training loss: 0.4701879657475294
Fold 3, Epoch 3, Training loss: 0.28895024414611076
Fold 3, Epoch 4, Training loss: 0.25486827254361283
Fold 3, Epoch 5, Training loss: 0.1632175177698378
Fold 3, Epoch 6, Training loss: 0.09802819444773207
Fold 3, Epoch 7, Training loss: 0.08221830913294272
Fold 3, Epoch 8, Training loss: 0.06142170591057336
Fold 3, Epoch 9, Training loss: 0.052943941956773335
Fold 3, Epoch 10, Training loss: 0.0407748905822338
Fold 3 completed in 162.09 seconds. Validation Accuracy: 89.75%
Starting fold 4
Fold 4, Epoch 1, Training loss: 0.9604696090769979
Fold 4, Epoch 2, Training loss: 0.47313785407922965
Fold 4, Epoch 3, Training loss: 0.33751317496057104
Fold 4, Epoch 4, Training loss: 0.2449286968768698
Fold 4, Epoch 5, Training loss: 0.16805734796927566
Fold 4, Epoch 6, Training loss: 0.12609869157648193
Fold 4, Epoch 7, Training loss: 0.07537118165003778
Fold 4, Epoch 8, Training loss: 0.11325982330053781
Fold 4, Epoch 9, Training loss: 0.04778336882807595
Fold 4, Epoch 10, Training loss: 0.05972826951883931
Fold 4 completed in 159.79 seconds. Validation Accuracy: 89.5%
Starting fold 5
Fold 5, Epoch 1, Training loss: 0.9624601394201802
Fold 5, Epoch 2, Training loss: 0.45164178575562164
Fold 5, Epoch 3, Training loss: 0.2820647888347111
Fold 5, Epoch 4, Training loss: 0.21849962686542915
Fold 5, Epoch 5, Training loss: 0.15015519304876834
Fold 5, Epoch 6, Training loss: 0.10517235837909764
Fold 5, Epoch 7, Training loss: 0.1062352280750607
Fold 5, Epoch 8, Training loss: 0.06429436839282496
Fold 5, Epoch 9, Training loss: 0.048738663496894645
Fold 5, Epoch 10, Training loss: 0.03997291060137785
Fold 5 completed in 160.76 seconds. Validation Accuracy: 88.75%
Starting fold 6
Fold 6, Epoch 1, Training loss: 0.875426122836307
Fold 6, Epoch 2, Training loss: 0.42183164836822357
Fold 6, Epoch 3, Training loss: 0.2932349002334924
Fold 6, Epoch 4, Training loss: 0.20906981258793214
Fold 6, Epoch 5, Training loss: 0.15578275667997984
Fold 6, Epoch 6, Training loss: 0.10406048480520207
Fold 6, Epoch 7, Training loss: 0.08247168063581715
Fold 6, Epoch 8, Training loss: 0.058895043617699594
Fold 6, Epoch 9, Training loss: 0.08478620537325937
Fold 6, Epoch 10, Training loss: 0.043897942363272165
Fold 6 completed in 162.90 seconds. Validation Accuracy: 90.75%
Starting fold 7
Fold 7, Epoch 1, Training loss: 0.9190621068783565
Fold 7, Epoch 2, Training loss: 0.4308308359664098
Fold 7, Epoch 3, Training loss: 0.3142692825831143
Fold 7, Epoch 4, Training loss: 0.23123466711392446
Fold 7, Epoch 5, Training loss: 0.17301224386401937
Fold 7, Epoch 6, Training loss: 0.11305546394623486
Fold 7, Epoch 7, Training loss: 0.08028131864750676
Fold 7, Epoch 8, Training loss: 0.08244570527654306
Fold 7, Epoch 9, Training loss: 0.06226922790942285
Fold 7, Epoch 10, Training loss: 0.036593609584281137
Fold 7 completed in 159.81 seconds. Validation Accuracy: 90.0%
Starting fold 8
Fold 8, Epoch 1, Training loss: 0.8798845642435867
Fold 8, Epoch 2, Training loss: 0.42190502168594207
Fold 8, Epoch 3, Training loss: 0.2959473877485874
Fold 8, Epoch 4, Training loss: 0.1988519330269995
Fold 8, Epoch 5, Training loss: 0.14478667802383413
Fold 8, Epoch 6, Training loss: 0.12053356520765651
Fold 8, Epoch 7, Training loss: 0.07546336513911003
Fold 8, Epoch 8, Training loss: 0.05622425333151709
Fold 8, Epoch 9, Training loss: 0.05879241148570338
Fold 8, Epoch 10, Training loss: 0.015980881823750164
Fold 8 completed in 161.50 seconds. Validation Accuracy: 87.25%
Starting fold 9
Fold 9, Epoch 1, Training loss: 1.0950307308045109
Fold 9, Epoch 2, Training loss: 0.6419182240435507
Fold 9, Epoch 3, Training loss: 0.47013076955238275
Fold 9, Epoch 4, Training loss: 0.3285408318042755
Fold 9, Epoch 5, Training loss: 0.24172803561771866
Fold 9, Epoch 6, Training loss: 0.19550481682593843
Fold 9, Epoch 7, Training loss: 0.1389076001653695
Fold 9, Epoch 8, Training loss: 0.09174405930118751
Fold 9, Epoch 9, Training loss: 0.06278416736873559
Fold 9, Epoch 10, Training loss: 0.08604970930836502
Fold 9 completed in 158.45 seconds. Validation Accuracy: 89.75%
Starting fold 10
Fold 10, Epoch 1, Training loss: 0.9953152740423659
Fold 10, Epoch 2, Training loss: 0.47788184010877016
Fold 10, Epoch 3, Training loss: 0.3423072673973784
Fold 10, Epoch 4, Training loss: 0.24503887388690382
Fold 10, Epoch 5, Training loss: 0.19253632759230327
Fold 10, Epoch 6, Training loss: 0.1389783417262071
Fold 10, Epoch 7, Training loss: 0.11089160516693265
Fold 10, Epoch 8, Training loss: 0.0745985341823425
Fold 10, Epoch 9, Training loss: 0.03988915941455459
Fold 10, Epoch 10, Training loss: 0.04689513423801523
Fold 10 completed in 159.55 seconds. Validation Accuracy: 91.0%
            Model  Fold  Accuracy  Macro Precision  Macro Recall  Macro F-Score  Micro Precision  Micro Recall  Micro F-Score
0             CNN     1    0.8700         0.869715      0.869039       0.868736           0.8700        0.8700         0.8700
1             CNN     2    0.8450         0.843747      0.839105       0.839790           0.8450        0.8450         0.8450
2             CNN     3    0.8525         0.855786      0.852072       0.852137           0.8525        0.8525         0.8525
3             CNN     4    0.8525         0.856175      0.853336       0.853815           0.8525        0.8525         0.8525
4             CNN     5    0.8650         0.871211      0.865239       0.866452           0.8650        0.8650         0.8650
5             CNN     6    0.8350         0.839808      0.832907       0.834421           0.8350        0.8350         0.8350
6             CNN     7    0.8500         0.850756      0.851419       0.850856           0.8500        0.8500         0.8500
7             CNN     8    0.8125         0.811886      0.811942       0.803477           0.8125        0.8125         0.8125
8             CNN     9    0.8400         0.845048      0.839862       0.841747           0.8400        0.8400         0.8400
9             CNN    10    0.8675         0.868787      0.870871       0.869713           0.8675        0.8675         0.8675
10  CNN Variant 2     1    0.7700         0.768275      0.766399       0.765801           0.7700        0.7700         0.7700
11  CNN Variant 2     2    0.7075         0.722086      0.699809       0.701672           0.7075        0.7075         0.7075
12  CNN Variant 2     3    0.7325         0.754166      0.735625       0.733539           0.7325        0.7325         0.7325
13  CNN Variant 2     4    0.7525         0.772101      0.751900       0.748269           0.7525        0.7525         0.7525
14  CNN Variant 2     5    0.7275         0.748420      0.723378       0.724356           0.7275        0.7275         0.7275
15  CNN Variant 2     6    0.7300         0.747669      0.737477       0.727547           0.7300        0.7300         0.7300
16  CNN Variant 2     7    0.7425         0.743060      0.741411       0.740162           0.7425        0.7425         0.7425
17  CNN Variant 2     8    0.7200         0.735017      0.711659       0.711467           0.7200        0.7200         0.7200
18  CNN Variant 2     9    0.6975         0.718949      0.697546       0.699992           0.6975        0.6975         0.6975
19  CNN Variant 2    10    0.7575         0.758453      0.759661       0.754742           0.7575        0.7575         0.7575
20  CNN Variant 3     1    0.9250         0.924733      0.924690       0.924338           0.9250        0.9250         0.9250
21  CNN Variant 3     2    0.9350         0.931413      0.932068       0.931668           0.9350        0.9350         0.9350
22  CNN Variant 3     3    0.8975         0.904461      0.897072       0.898029           0.8975        0.8975         0.8975
23  CNN Variant 3     4    0.8950         0.894936      0.895812       0.895047           0.8950        0.8950         0.8950
24  CNN Variant 3     5    0.8875         0.899387      0.888549       0.888528           0.8875        0.8875         0.8875
25  CNN Variant 3     6    0.9075         0.908246      0.909540       0.908043           0.9075        0.9075         0.9075
26  CNN Variant 3     7    0.9000         0.901662      0.902187       0.901418           0.9000        0.9000         0.9000
27  CNN Variant 3     8    0.8725         0.868000      0.869748       0.868353           0.8725        0.8725         0.8725
28  CNN Variant 3     9    0.8975         0.896057      0.897767       0.896528           0.8975        0.8975         0.8975
29  CNN Variant 3    10    0.9100         0.909952      0.910532       0.910208           0.9100        0.9100         0.9100

Average Metrics for Each Model Across All Folds:
           Model  Fold  Accuracy  Macro Precision  Macro Recall  Macro F-Score  Micro Precision  Micro Recall  Micro F-Score
0            CNN   5.5   0.84900         0.851292      0.848579       0.848115          0.84900       0.84900        0.84900
1  CNN Variant 2   5.5   0.73375         0.746820      0.732487       0.730755          0.73375       0.73375        0.73375
2  CNN Variant 3   5.5   0.90275         0.903885      0.902797       0.902216          0.90275       0.90275        0.90275